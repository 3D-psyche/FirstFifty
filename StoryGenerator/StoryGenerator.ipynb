{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordPOSTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanford POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the path to java.exe for nltk\n",
    "java_path = \"F:/java/java/bin/java.exe\"\n",
    "    \n",
    "os.environ['JAVAHOME'] = java_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a StanfordPOStagger object\n",
    "model_filename = \"E:\\Stanford Taggers\\stanford-postagger-full-2015-04-20\\stanford-postagger-full-2015-04-20\\models\"\n",
    "path_to_jar = \"E:\\Stanford Taggers\\stanford-postagger-full-2015-04-20\\stanford-postagger-full-2015-04-20\"\n",
    "\n",
    "st = StanfordPOSTagger(model_filename+\"\\english-bidirectional-distsim.tagger\", path_to_jar+\"\\stanford-postagger.jar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return a random plot form data frame with Title and Genre\n",
    "def sel_plot(df):\n",
    "    # choosing a random value \n",
    "    num = random.choice([100, 150, 200, 250])\n",
    "    val = random.randrange(1,num)\n",
    "\n",
    "    print(f\"Selected value : {val}\")\n",
    "    \n",
    "    ## re-framing the data\n",
    "    plots = {}\n",
    "    for index,row in df.iterrows():\n",
    "        plots[row[\"Title\"]] = {\"Genre\":row[\"Genre\"], \"Plot\": row[\"Plot\"]}\n",
    "        if index == val: break\n",
    "            \n",
    "    # choosing a random title\n",
    "    titles = list(plots.keys())\n",
    "    sel_movie = random.choice(titles)\n",
    "    \n",
    "    return plots[sel_movie]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to tokenize the plot into Parts of Speech\n",
    "# func to get abb of pos\n",
    "def get_abb(tag_obj):\n",
    "    tag_dct = {}\n",
    "    \n",
    "    if type(tag_obj) == str: tags = st.tag(tag_obj.split())\n",
    "    elif type(tag_obj) == list: tags = st.tag(tag_obj)\n",
    "    for word,tag in tags:\n",
    "        tag_dct[word] = tag,abb[tag] \n",
    "        \n",
    "    return tag_dct \n",
    "\n",
    "# func to get tokens\n",
    "def pos_tokenizer(plot_obj):\n",
    "    plot = plot_obj[\"Plot\"]\n",
    "    get_abb(plot)\n",
    "      \n",
    "    return plot_obj[\"Genre\"],tag_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_tokenizer(sel_plot(req_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetching the movie data\n",
    "movies_data = pd.read_csv(\"wiki_movie_plots_deduped.csv\", encoding=\"utf-8\")\n",
    "\n",
    "req_data = movies_data[[\"Title\", \"Genre\", \"Plot\"]]\n",
    "req_data = req_data[req_data[\"Genre\"] != \"unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning the data\n",
    "# cleaning the plot encoding\n",
    "def clean_str(st):\n",
    "    for ch in st :\n",
    "        if ch in string.punctuation:\n",
    "            st = st.replace(ch,\"\")\n",
    "    st = st.encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "    return st\n",
    "\n",
    "req_data[\"Plot\"] = req_data[\"Plot\"].apply(lambda x:clean_str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS tags Abrrevations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\"\n",
    "res = requests.get(url)\n",
    "soup = bs(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.select(\"table tr\")\n",
    "\n",
    "abb = {}\n",
    "for row in table[1:]:\n",
    "    cols = row.find_all(\"td\")\n",
    "    col_lst = [col.get_text() for col in cols][1:]\n",
    "    abb[col_lst[0].strip()] = col_lst[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_wrds = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_abb = get_abb(tmp_wrds[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_dct = {}\n",
    "\n",
    "for key,value in eng_abb.items():\n",
    "    if value[1] not in eng_dct:\n",
    "        eng_dct[value[1]] = list()\n",
    "    eng_dct[value[1]].append(key)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StoryGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected value : 10\n"
     ]
    }
   ],
   "source": [
    "res = pos_tokenizer(sel_plot(req_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = res[0]\n",
    "pos_tup = res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(pos_tup.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = random.randrange(1, 20)\n",
    "choosen = []\n",
    "for i in range(num):\n",
    "    choosen.append(random.choice(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a Determiner:a\n",
      "Enter a Verb, 3rd person singular present:live\n",
      "Enter a Noun, singular or mass:Ben\n",
      "Enter a Verb, non-3rd person singular present:eat\n",
      "Enter a Determiner:the\n",
      "Enter a Adjective:brave\n",
      "Enter a Verb, non-3rd person singular present:jump\n",
      "Enter a Verb, base form:love\n",
      "Enter a Adjective:angry\n",
      "Enter a Noun, singular or mass:sally\n",
      "Enter a Verb, 3rd person singular present:drank\n",
      "Enter a Possessive pronoun:his\n",
      "Enter a Noun, singular or mass:pen\n"
     ]
    }
   ],
   "source": [
    "# choosen\n",
    "new_words = []\n",
    "for title,tup in pos_tup.items():\n",
    "    if title in choosen:\n",
    "        new_word = input(f\"Enter a {tup[1]}:\")\n",
    "        new_words.append(new_word)\n",
    "    else:\n",
    "        new_words.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a film live about a Ben who eat to the suburbs hoping for brave life Things jump love angry and sally gets violent drank throwing crockery leading his pen'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(new_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
